{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-21T16:35:54.891839800Z",
     "start_time": "2024-02-21T16:35:52.285259800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\talia\\AppData\\Local\\Temp\\ipykernel_17752\\17788862.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import re\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "def preprocess_script(script):\n",
    "    # Function to clean the script\n",
    "    def clean_script(script):\n",
    "        # Remove comments from the script\n",
    "        script = re.sub(r'#.*$', ' ', script, flags=re.MULTILINE)\n",
    "\n",
    "        # Remove special characters and reduce consecutive spaces\n",
    "        cleaned_script = re.sub(r'\\s+', ' ', script)\n",
    "\n",
    "        # Remove tabs and newlines\n",
    "        cleaned_script = cleaned_script.replace('\\t', ' ').replace('\\n', ' ')\n",
    "\n",
    "        # Remove punctuation\n",
    "        cleaned_script = re.sub(r'[^\\w\\s]', ' ', cleaned_script).lower()\n",
    "\n",
    "        return cleaned_script\n",
    "\n",
    "    # Clean the input script\n",
    "    clean = clean_script(script)\n",
    "\n",
    "    # Load the TF-IDF vectorizer\n",
    "    with open('vectorizer.pkl', 'rb') as file:\n",
    "        vectorizer = pickle.load(file)\n",
    "\n",
    "    # Load the SelectKBest instance\n",
    "    with open('selector.pkl', 'rb') as file:\n",
    "        selector = pickle.load(file)\n",
    "\n",
    "    # Load the selected feature names DataFrame\n",
    "    X_selected_df = pd.read_pickle('selected_features.pkl')\n",
    "\n",
    "    # Apply the TF-IDF vectorizer to the new data\n",
    "    X_tfidf = vectorizer.transform([clean])\n",
    "\n",
    "    # Apply the loaded SelectKBest instance to the TF-IDF transformed data\n",
    "    X_new_selected = selector.transform(X_tfidf)\n",
    "\n",
    "    # Convert the selected features to a DataFrame using the previously selected feature names\n",
    "    X_new_selected_df = pd.DataFrame(X_new_selected.toarray(), columns=X_selected_df.columns)\n",
    "\n",
    "    # Feature engineering\n",
    "    def text_length(script):\n",
    "        return len(script)\n",
    "\n",
    "    def entropy(script):\n",
    "        character_counts = Counter(script)\n",
    "        total_characters = len(script)\n",
    "        probabilities = [count / total_characters for count in character_counts.values()]\n",
    "        entropy_value = -sum(probability * math.log2(probability) for probability in probabilities)\n",
    "        return entropy_value\n",
    "\n",
    "    def punctuation_count(script):\n",
    "        return len(re.findall(r'[^\\w\\s]', script))\n",
    "\n",
    "    def function_count(script):\n",
    "        function_keywords = ['function', 'procedure']\n",
    "        return sum(script.count(keyword) for keyword in function_keywords)\n",
    "\n",
    "    def numeric_literal_count(script):\n",
    "        return len(re.findall(r'\\b\\d+\\b', script))\n",
    "\n",
    "    def string_literal_count(script):\n",
    "        return len(re.findall(r'\"([^\"]*)\"', script))\n",
    "\n",
    "    def has_error_handling(script):\n",
    "        error_handling_keywords = ['try', 'except', 'catch']\n",
    "        return any(keyword in script for keyword in error_handling_keywords)\n",
    "\n",
    "    def has_urls_or_ips(script):\n",
    "        return bool(re.search(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+|\\d+\\.\\d+\\.\\d+\\.\\d+', script))\n",
    "\n",
    "    def has_obfuscation_indicators(script):\n",
    "        obfuscation_patterns = [\n",
    "            r'\\b(?:\\w+\\s*\\+\\s*\\w+)',\n",
    "            r'\\b(?:[a-zA-Z]\\s*=\\s*[^;]*\\bchr\\s*\\(\\s*\\w+\\s*\\+\\s*\\d+\\s*\\)\\s*;\\s*)+',\n",
    "            r'0x[\\da-fA-F]+',\n",
    "            r'(?:\\\\x[0-9a-fA-F]{2}|\\\\u[0-9a-fA-F]{4}|\\\\U[0-9a-fA-F]{8})',\n",
    "            r'\\b(?:Add-Type|dllimport|virtualalloc|createthread|memset)\\b',\n",
    "            r'\\b(?:eval|exec|decode|encode|obfuscate)\\b'\n",
    "        ]\n",
    "        return any(re.search(pattern, script) for pattern in obfuscation_patterns)\n",
    "\n",
    "    def has_suspicious_words(script):\n",
    "        disclosure_keywords = ['downloadfile','password', 'secret', 'key', 'token', 'downloadstring',\n",
    "                            'dllimport', 'programdata', 'new object', 'appdata']\n",
    "        return any(keyword in script for keyword in disclosure_keywords)\n",
    "\n",
    "    def longest_string_length(script):\n",
    "        string_literals = re.findall(r'\"([^\"]*)\"', script)\n",
    "        if not string_literals:\n",
    "            return 0\n",
    "        longest_length = max(len(string_literal) for string_literal in string_literals)\n",
    "        return longest_length\n",
    "\n",
    "    length = text_length(clean)\n",
    "    ent = entropy(script)\n",
    "    punc_count = punctuation_count(script)\n",
    "    func_count = function_count(clean)\n",
    "    num_lit_count = numeric_literal_count(clean)\n",
    "    str_lit_count = string_literal_count(script)\n",
    "    err_handling = has_error_handling(clean)\n",
    "    urls_ips = has_urls_or_ips(script)\n",
    "    obf_indicators = has_obfuscation_indicators(clean)\n",
    "    suspicious_words = has_suspicious_words(clean)\n",
    "    longest_str_length = longest_string_length(script)\n",
    "\n",
    "    # Create a DataFrame with the extracted features\n",
    "    new_features = pd.DataFrame({\n",
    "        'text_length': [length],\n",
    "        'function_count': [func_count],\n",
    "        'numeric_literal_count': [num_lit_count],\n",
    "        'has_error_handling': [int(err_handling)], \n",
    "        'has_obfuscation_indicators': [int(obf_indicators)],\n",
    "        'has_suspicious_words': [int(suspicious_words)],  \n",
    "\n",
    "        'Entropy': [ent],\n",
    "        'punctuation_count': [punc_count],\n",
    "        'longest_string_length': [longest_str_length],\n",
    "        'string_literal_count': [str_lit_count],\n",
    "        'has_urls_or_ips': [int(urls_ips)]       \n",
    "    })\n",
    "\n",
    "    # Concatenate the new features DataFrame with the existing DataFrame containing selected features\n",
    "    X_new_selected_df_with_features = pd.concat([X_new_selected_df, new_features], axis=1)\n",
    "\n",
    "    return X_new_selected_df_with_features"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\talia\\PycharmProjects\\UI_cyber\\.venv\\lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 1.3.0 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\talia\\PycharmProjects\\UI_cyber\\.venv\\lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator TfidfVectorizer from version 1.3.0 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\talia\\PycharmProjects\\UI_cyber\\.venv\\lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator SelectKBest from version 1.3.0 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "   0x00  0x00 0x00  0x00 0x00 0x00  0x00 0x00 0x60  0x00 0x00 0x68  0x00 0x10  \\\n0   0.0        0.0             0.0             0.0             0.0        0.0   \n\n   0x00 0x10 0x00  0x00 0x56  0x00 0x60  0x00 0x60 0x89  ...  function_count  \\\n0             0.0        0.0        0.0             0.0  ...               0   \n\n   numeric_literal_count  has_error_handling  has_obfuscation_indicators  \\\n0                      0                   0                           0   \n\n   has_suspicious_words   Entropy  punctuation_count  longest_string_length  \\\n0                     0  3.801109                  0                      0   \n\n   string_literal_count  has_urls_or_ips  \n0                     0                0  \n\n[1 rows x 1011 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0x00</th>\n      <th>0x00 0x00</th>\n      <th>0x00 0x00 0x00</th>\n      <th>0x00 0x00 0x60</th>\n      <th>0x00 0x00 0x68</th>\n      <th>0x00 0x10</th>\n      <th>0x00 0x10 0x00</th>\n      <th>0x00 0x56</th>\n      <th>0x00 0x60</th>\n      <th>0x00 0x60 0x89</th>\n      <th>...</th>\n      <th>function_count</th>\n      <th>numeric_literal_count</th>\n      <th>has_error_handling</th>\n      <th>has_obfuscation_indicators</th>\n      <th>has_suspicious_words</th>\n      <th>Entropy</th>\n      <th>punctuation_count</th>\n      <th>longest_string_length</th>\n      <th>string_literal_count</th>\n      <th>has_urls_or_ips</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3.801109</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 1011 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the function\n",
    "preprocess_script(\"Your PowerShell script goes here\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T16:37:19.449929300Z",
     "start_time": "2024-02-21T16:37:18.873102800Z"
    }
   },
   "id": "3f84f7d8fe8bd52",
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
